{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c2ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
    "df = df[['captionID', 'sentence1', 'sentence2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93901edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('identity_terms.txt', 'r')\n",
    "id_terms = []\n",
    "for line in file:\n",
    "    term = line.strip().lower()\n",
    "    id_terms.append(term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e247c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prems = df.drop_duplicates(subset=['captionID'])['sentence1'].to_dict()\n",
    "hyps = df['sentence2'].drop_duplicates().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbab8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "\n",
    "from text_tools import process, count_words\n",
    "\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "def bias_info(target, corpus, single_count, threshold=10):\n",
    "    N = len(corpus)\n",
    "    pair_count = Counter()\n",
    "\n",
    "    if single_count[target] == 0:\n",
    "        return None\n",
    "\n",
    "    pair_pmi = dict()\n",
    "    pair_location = defaultdict(list) \n",
    "    \n",
    "    for idx, uttr in corpus.items():\n",
    "        if target in uttr:\n",
    "            for w in uttr:\n",
    "                pair_count[w] += 1 \n",
    "                pair_location[w].append(idx)\n",
    "    \n",
    "    for w in pair_count:\n",
    "        if single_count[w] >= threshold:\n",
    "            pmi = math.log2(N * pair_count[w]) - math.log2(single_count[target] * single_count[w])\n",
    "            pair_pmi[w] = pmi \n",
    "\n",
    "    return pair_pmi, pair_location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804a9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_prems = process(prems, stopwords)\n",
    "single_count_prems = count_words(processed_prems)\n",
    "\n",
    "processed_hyps = process(hyps, stopwords)\n",
    "single_count_hyps = count_words(processed_prems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e4dda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Identity Terms  Num of Prems\n",
      "2              man         38667\n",
      "0            woman         20358\n",
      "125          young         12161\n",
      "35           white         11769\n",
      "32           black         10932\n",
      "4             girl          8912\n",
      "3              men          8900\n",
      "6              boy          8735\n",
      "1            women          4926\n",
      "5            girls          2505\n",
      "33           asian          2184\n",
      "7             boys          1862\n",
      "121            old          1477\n",
      "14            male          1360\n",
      "13          female          1276\n",
      "122        elderly           958\n",
      "37        american           558\n",
      "36         african           517\n",
      "15          mother           353\n",
      "49          indian           291\n"
     ]
    }
   ],
   "source": [
    "prems_data = {\n",
    "    'Identity Terms': id_terms,\n",
    "    'Num of Prems' : [single_count_prems[term] for term in id_terms]\n",
    "}\n",
    "\n",
    "prems_id_count = pd.DataFrame(prems_data)\n",
    "prems_id_count = prems_id_count[prems_id_count['Num of Prems'] >= 10]\n",
    "prems_id_count = prems_id_count.sort_values(by='Num of Prems', ascending=False)\n",
    "\n",
    "print(prems_id_count.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d28cab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Identity Terms  Num of Hyps\n",
      "2              man        38667\n",
      "0            woman        20358\n",
      "125          young        12161\n",
      "35           white        11769\n",
      "32           black        10932\n",
      "4             girl         8912\n",
      "3              men         8900\n",
      "6              boy         8735\n",
      "1            women         4926\n",
      "5            girls         2505\n",
      "33           asian         2184\n",
      "7             boys         1862\n",
      "121            old         1477\n",
      "14            male         1360\n",
      "13          female         1276\n",
      "122        elderly          958\n",
      "37        american          558\n",
      "36         african          517\n",
      "15          mother          353\n",
      "49          indian          291\n"
     ]
    }
   ],
   "source": [
    "hyps_data = {\n",
    "    'Identity Terms': id_terms,\n",
    "    'Num of Hyps' : [single_count_hyps[term] for term in id_terms]\n",
    "}\n",
    "\n",
    "hyps_id_count = pd.DataFrame(hyps_data)\n",
    "hyps_id_count = hyps_id_count[hyps_id_count['Num of Hyps'] >= 10]\n",
    "hyps_id_count = hyps_id_count.sort_values(by='Num of Hyps', ascending=False)\n",
    "\n",
    "print(hyps_id_count.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e03878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_id_terms = [\n",
    "    'man', \n",
    "    'men',\n",
    "    'boy',\n",
    "    'male',\n",
    "    'woman',\n",
    "    'women',\n",
    "    'girl',\n",
    "    'female',\n",
    "    'caucasian',\n",
    "    'african',\n",
    "    'asian'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a92a1e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "prems_bias = defaultdict(dict)\n",
    "for term in select_id_terms:\n",
    "    pair_pmi, pair_locations = bias_info(term, processed_prems, single_count_prems)\n",
    "    prems_bias[term]['pmi'] = pair_pmi\n",
    "    prems_bias[term]['locations'] = pair_locations\n",
    "\n",
    "hyps_bias = defaultdict(dict)\n",
    "for term in select_id_terms:\n",
    "    pair_pmi, pair_locations = bias_info(term, processed_hyps, single_count_hyps)\n",
    "    hyps_bias[term]['pmi'] = pair_pmi\n",
    "    hyps_bias[term]['locations'] = pair_locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d25c7209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Terms       PMI\n",
      "10         asian  6.113303\n",
      "403    southeast  5.627876\n",
      "99       descent  5.275054\n",
      "267         east  4.528341\n",
      "315     language  4.265306\n",
      "1315      pastel  3.997826\n",
      "1546      likely  3.911669\n",
      "1803     patrick  3.890911\n",
      "1334      petals  3.890911\n",
      "752         pigs  3.791375\n",
      "194    styrofoam  3.791375\n",
      "2102  schoolgirl  3.791375\n",
      "1918     shading  3.791375\n",
      "398       badges  3.791375\n",
      "831      fabrics  3.791375\n"
     ]
    }
   ],
   "source": [
    "output_pairs = prems_bias['asian']['pmi']\n",
    "output_df = pd.DataFrame.from_dict(output_pairs, orient='index', columns=['PMI']).reset_index()\n",
    "output_df.columns = ['Terms', 'PMI']\n",
    "output_df = output_df.sort_values(by='PMI', ascending=False)\n",
    "print(output_df.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f187bbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[496623, 496632]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prems_bias['asian']['locations']['schoolgirl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b70950a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'captionID': '4837948080.jpg#0',\n",
       " 'sentence1': 'An Asian schoolgirl in a typical schoolgirl uniform, dark pullover, plaid skirt, and knee socks with penny loafers.',\n",
       " 'sentence2': 'A girl is wearing a shirt, skirt, socks, and shoes.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[496632].to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ez_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
